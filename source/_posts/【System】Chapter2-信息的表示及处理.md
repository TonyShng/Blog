---
title: '【System】Chapter2:信息的表示及处理'
date: 2021-07-30 08:05:15
categories: "System"
tags:
    - System
urlname:
keywords: System
---

现代计算机存储和处理的信息以二值信号表示。这些微不足道的二进制数字，或者称为*位（bit）*，形成了数字革命的基础。二值信号能够很容易地被表示、存储和传输，例如可以表示为穿孔卡片上有洞或者无洞、导线上的高电压或者低电压，或者顺时针或逆时针的磁场。对二值信号进行存储和执行计算的电子电路非常简单和可靠，制造商能够在一个单独的硅片上集成数百万甚至数十亿个这样的电路。

<!-- more -->

孤立的讲，单个的位不是非常有用。然而，当把位组合在一起，再加上某种解释（interpretation），即赋予不同的可能位模式以含义，我们就能够表示任何有限集合的元素。

*无符号*（unsigned）编码基于传统的二进制表示法，表示大于或者等于零的数字。*补码*（two's-complement）编码是表示有符号整数的最常见的方式，有符号整数就是可以为正或者为负的数字。浮点数（floating-point）编码是表示实数的科学计数法的以2为基数的版本。计算机用这些不同的表示方法实现算数运算。

计算机的表示法是用有限数量的位来对一个数字编码，因此，当结果太大以至于不能表示时，某些运算就会*溢出*（overflow）。溢出会导致某些令人吃惊的后果。另一方面，整数的计算机运算满足人们所熟知的真正整数运算的许多性质。例如，利用乘法的结合律和交换律，计算下面任何一个C表达式，都会得出一致的结果。计算机可能没有产生期望的结果，但是至少它是一致的！

浮点运算有完全不同的数学属性。虽然溢出会产生特殊的值+♾️，但是一组正数的乘积总是正的。由于表示的精度有限，浮点运算是不可结合的。整数运算和浮点数运算会有不同的数学属性是因为它们处理数字表示有限性的方式不同——整数的表示虽然智能编码一个相对较小的数值范围，但是这种表示是精确的；而浮点数虽然可以编码一个较大的数值范围，但是这种表示只是近似的。

通过研究数字的实际表示，我们能够了解可以表示的值的范围和不同算术运算的属性。为了使编写的程序能在全部数值范围内正确工作，而且具有可以跨越不同机器、操作系统和编译器组合的可移植性，了解这种属性是非常重要的。后面我们会讲到，大量计算机的安全漏洞都是由于计算机算数运算的微妙细节引发的。在早期，当人们碰巧触发了程序漏洞，只会给人们带来一些不便，但是现在，有众多的黑客企图利用他们能找到的任何漏洞，不经过授权就进入他人的系统。这就要求程序员有更多的责任和义务，去了解他们的程序如何工作，以及如何被迫产生不良的行为。

计算机用几种不同的二进制表示形式来编码数值。通过直接操作数字的位级表示，我们得到了几种进行算术运算的方式。理解这些技术对于理解编译器产生的机器级代码是很重要的，编译器会试图优化算术表达式求值的性能。

#### 2.1 信息存储

大多数计算机使用8位的块，或者*字节*（byte），作为最小的可寻址的内存单位，而不是访问内存中单独的位。机器级程序将内存视为一个非常大的字节数组，称为*虚拟内存*（virtual memory）。内存的每个字节都由一个唯一的数字来标识，称为它的*地址*（address），所有可能地址的集合就称为虚拟地址空间（virtual address space）。顾名思义，这个虚拟地址空间只是一个展现给机器级程序的概念性映像。实际的实现是将动态随机访问存储器（DRAM）、内存、磁盘存储器、特殊硬件和操作系统软件结合起来，为程序提供一个看上去统一的字节数组。

接下来，我们将讲述编译器和运行时系统是如何将存储器空间划分为更可管理的单元，来存放不同的*程序对象*（program object），即程序数据、指令和控制信息。可以用各种机制来分配和管理程序不同部分的存储。这种管理完全是在虚拟地址空间里完成的。例如，C语言中一个指针的值（无论它指向一个整数、一个结构或是某个其他程序对象）都是某个存储块的第一个字节的虚拟地址。C编译器还把每个指针和类型信息联系起来，这样就可以根据指针值的类型，生成不同的机器代码来访问存储在指针所指向位置处的值。尽管C编译器维护着这个类型信息，但是它生成的实际机器级程序并不包含关于数据类型的信息。每个程序对象可以简单地视为一个字节块，而程序本身就是一个字节序列。

> 指针是C语言的一个重要特性。它提供了引用数据结构（包括数组）的元素机制。与变量类似，指针也有两个方面：值和类型。它的值表示某个对象的位置，而它的类型表示那个位置上所存储对象的类型（比如整数或者浮点数）。

##### 2.1.1 十六进制表示法

一个字节由8位组成。在二进制表示法中，它的值域是0000 0000 ～ 1111 1111。如果看成十进制整数，它的值域就是 0～255。两种符号表示法对于描述位模式来说都不是非常方便。二进制表示法太冗长，而十进制表示法与位模式的互相转化很麻烦。替代的方法是，以16为基数，或者叫做*十六进制*（hexadecimal）数，来表示位模式。十六进制（简写为'hex'）使用数字 0～9 以及字符 A～F 来表示16个可能的值。

在C语言中，以 0x 或 Ox 开头的数字常量被认为是十六进制的值。字符 A～F 既可以是大写，也可以是小写，甚至可以是大小写混合。

编写机器级程序的一个常见任务就是在位模式的十进制、二进制和十六进制表示之间人工转换。二进制和十六进制之间的转换比较简单直接，因为可以执行一个十六进制数字的转换——即四位表示一位。一个简单的窍门是，记住十六进制数字A、C和F相应的十进制值。而对于把十六进制值B、D和E转换成十进制值，则可以通过计算它们与前三个值的相对关系来完成。

> 较大数值的十进制和十六进制之间的转换，最好是让计算机或者计算器来完成。

##### 2.1.2 字数据大小

每台计算机都有一个*字长*（word size），指明指针数据的*标称大小*（normal size）。因为虚拟地址是以这样的一个字来编码的，所以字长决定的最重要的系统参数就是虚拟地址空间的最大大小。也就是说，对于一个字长位 w 位的机器而言，虚拟地址的范围为 0 ~ $2^w -1$，程序最多访问$2^w$个字节。

最近这些年，出现了大规模的从32位字长机器到64位字长机器到迁移。这种情况首先出现在为大型科学和数据库应用设计的高端机器上，之后是台式机和笔记本电脑，最近则出现在智能手机的处理器上。32位字长限制虚拟地址空间为4千兆字节（写作4GB），也就是说，刚刚超过$4 \times 10^9$字节。扩展到64位字长使得虚拟地址空间为16EB，大约是$1.84 \times 10^{19}$​字节。

大多数64位机器也可以运行32位机器编译的程序，这是一种向后兼容。我们将程序称为“32位程序”或“64位程序”时，区别在于该程序时如何编译的，而不是其运行的机器类型。

计算机和编译器支持多种不同方式编码的数字格式，如不同长度的整数和浮点数。比如，许多机器都有处理单个字节的指令，也有处理表示为2字节、4字节或者8字节整数的指令，还有些指令支持表示为4字节和8字节的浮点数。

C语言支持整数和浮点数的多种数据格式。有些数据类型的确切字节数依赖于程序是如何被编译的。整数或者为有符号的，即可以表示负数、零和正数；或者为无符号的，即只能表示非负数。C的数据类型char 表示一个单独的字节。尽管"char"是由于它被用来存储文本串中的单个字符这一事实而得名，但它也能被用来存储整数值。数据类型 short、int 和 long 可以提供各种数据大小。即使是为64位系统编译，数据类型 int 通常也只有4个字节。数据类型 long 一般在32位程序中为4字节，在64位程序中则为8字节。

为了避免由于依赖“典型”大小和不同编译器设置带来的奇怪行为，ISO C99引入了一类数据类型，其大小是固定的，不随编译器和机器设置而变化。其中就有数据类型 int32_t 和 int64_t，它们分别为4个字节和8个字节。使用确定大小的整数类型是程序员准确控制数据表示的最佳途径。

大部分数据类型都编码为有符号数值，除非有前缀关键字 unsigned 或对确定大小的数据类型使用了特定的无符号声明。数据类型 char 是一个例外。尽管大多数编译器和机器将它们视为有符号数，但C标准不保证这一点。相反，正如方括号指示的那样，程序员应该用有符号字符的声明来保证其为一个字节的有符号数值。不过，在很多情况下，程序行为对数据类型 char 是有符号的还是无符号的并不敏感。

程序员应该力图使他们的程序在不同的机器和编译器上可移植。可移植性的一个方面就是使程序对不同数据类型的确切大小不敏感。C语言标准对不同数据类型的数字范围设置了下界，但是却没有上界。

##### 2.1.3 寻址和字节顺序

对于跨越多字节的程序对象，我们必须建立两个规则：这个对象的地址是什么，以及在内存中如何排列这些字节。在几乎所有的机器上，多字节对象都被存储为连续的字节序列，对象的地址为所使用字节中最小的地址。

排列表示一个对象的字节有两个通用的规则。考虑一个 w 位的整数，其位表示为[x<sub>w-1</sub>, x~w-2~, ..., x~1~, x~0~]，其中x~w-1~是最高有效位，而x~0~是最低有效位。假设 w 是8的倍数，这些位就能被分组成为字节，其中最高有效字节包含位[x~w-1~, x~w-2~, ... , x~w-8~]，而最低有效字节包含位[x~7~, x~6~, ... , x~0~]，其他字节包含中间的位。某些机器选择在内存中按照从最低有效字节到最高有效字节的顺序存储对象，而另一些机器则是按照从最高有效字节到最低有效字节到顺序存储。前一种规则——最低有效字节在最前面的方式，成为*小端法*(little endian)。后一种规则——最高有效字节在最前面的方式，称为*大端法*(big endian)。

许多比较新的微处理器是*双端法*(big-endian)，也就是说可以把它们配置成作为大端或者小端的机器运行。然而，实际情况是：一旦选择了特定操作系统，那么字节顺序也就固定下来了。

对于大多数应用程序猿来说，其机器所使用的字节顺序是完全不可见的。无论是哪种类型的机器所编译的程序都会得到同样的结果。不过有时候，字节顺序会成为问题。首先是在不同类型的机器之间通过网络传送二进制数据时，一个常见的问题是当小端法机器产生的数据被发送到大端法机器或者反过来时，接受程序会发现，字里的字节成了反序的。为了避免这类问题，网络应用程序的代码编写必须遵守已建立的关于字节顺序的规则，以确保发送方机器将它的内部表示转换成网络标准，而接收方机器则将网络标准转换为它的内部表示。

第二种情况是，当阅读表示整数数据的字节序列时字节顺序也很重要。这通常发生在检查机器级程序时。

字节顺序变得重要的第三种情况是编写规避正常的类型系统的程序时。在C语言中，可以通过使用*强制类型转换*(cast)或*联合*(union)来允许以一种数据类型引用一个对象，而这种数据类型与创建这个对象时定义的数据类型不同。大多数应用编程都强烈不推荐这种编码技巧，但是它们对系统级编程来说是非常有用的，甚至是必须的。

##### 2.1.4 表示字符串

C语言中字符串被编码为一个以 null (其值为 0 )的字符结尾的字符数组。每个字符都由某个标准编码来表示，最常见的是 ASCII 字符串。在使用ASCII 码作为字符码的任何系统上都将得到相同的结果，与字节顺序和字大小规则无关。因此，文本数据比二进制数据具有更强的平台独立性。

> 基本编码，称为 Unicode 的“统一字符集”，使用32位来表示字符。这好像要求文本串中每个字符要占4个字节。不过，可以有一些替代编码，常见的字符只需要1个或2个字节，而不太常用的字符需要多一些的字节数。特别地，UTF-8 表示将每个字符编码为一个字节序列，这样标准 ASCII 字符还是使用和它们在 ASCII 中一样的单字节编码，这也就意味着所有的 ASCII 字节序列用ASCII码表示和用 UTF-8 表示是一样的。

##### 2.1.5 表示代码

当我们在机器上编译，生成字节表示的机器代码，我们会发现指令编码是不同的。不同的机器类型使用不同的且不兼容的指令和编码方式。即使是完全一样的进程，运行在不同的操作系统上也会有不同的编码规则，因此二进制代码是不兼容的。二进制代码很少能在不同机器和操作系统组合之间移植。

计算机系统的一个基本概念就是，从机器的角度来看，程序仅仅是字节序列。机器没有关于原始源程序的任何信息，除了可能有些用来帮助调试的辅助表以外。

##### 2.1.6 布尔代数简介

































